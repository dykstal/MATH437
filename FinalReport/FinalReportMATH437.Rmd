---
pdf_document: default
output: pdf_document
html_document: default
header-includes: \usepackage{amsmath,calc}
---

\begin{center}
\huge{Dank Title Here}

\large{Aidan Dykstal, Edward Hammond, \& Lilia James} \\
\large{May $4^{\text{th}}$, 2020}
\end{center}

```{r setup, include=FALSE}
# KnitR Setup for RMarkdown
knitr::opts_chunk$set(echo = TRUE)
```

# 1 \hspace{0.25cm} Introduction
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Introduce the Data & the Data Source             %
[//]: 2) Introduce Clear Research Questions               %
[//]: 3) Preview the Model that will be used to Solve     %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this project, we choose to focus on a dataset which includes information regarding people of the Pima Indian Tribe and their relationship to diabetes. The dataset contains 768 observations over 9 variables. The variables are as follow:

\begin{enumerate}

\item Number of times pregnant -
\item Plasma glucose concentration at two hours in oral glucose tolerance test
\item Diastolic blood pressure in mm/hg
\item Tricep skinfold thickness in mm
\item Two hour serum insulin concentration $\mu/ml$
\item Body Mass Index kg/$m^2$ 
\item Diabetes pedigree function
\item Age in years
\item Diabetic status - This categorical variable

\end{enumerate}
\newpage

# 2 \hspace{0.25cm} The Quadratic Discriminant Analysis Approach
## 2.1 \hspace{0.25cm} Assumptions
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Clearly Explain Assumptions Needed for Validity  %
[//]: 2) Discuss Limitations of the Approach              %
[//]: 3) Preview the Checks of Assumptions/Limitations    %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DANKNUGGIES.

\newpage

## 2.2 \hspace{0.25cm} Model Construction Methods
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Describe Procedures to Construct the Model       %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DANKNUGGIES.

## 2.3 \hspace{0.25cm} Application to the STUDY-GOES-HERE 
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Explain Model's Answers to Research Questions    %
[//]: 2) Contextualize Assumptions and Limitations to     %
[//]:    the Problem of Interest                          %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DANKNUGGIES.

## 2.4 \hspace{0.25cm} Model Limitations \& Appropriateness 
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Discuss the Limitations of this Approach as Seen %
[//]:    in the Results                                   %
[//]: 2) Carefully Check Model Assumptions and Validity:  %
[//]:    e.g., if Using Regression:                       %
[//]:       i) Thoroughly Examine Model Appropriateness   %
[//]:       ii) Plot Residuals vs. Fitted Values          %
[//]:       iii) Identify High-Leverage Points            %
[//]:       iv) Identify Influential Points. Fit the      %
[//]:           Model with/without Influential Points     %
[//]:       v) Identify any Outliers                      %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DANKNUGGIES.

\newpage

# 3 \hspace{0.25cm} The Logistic Regression Approach
## 3.1 \hspace{0.25cm} Assumptions
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Clearly Explain Assumptions Needed for Validity  %
[//]: 2) Discuss Limitations of the Approach              %
[//]: 3) Preview the Checks of Assumptions/Limitations    %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DANKNUGGIES. 

## 3.2 \hspace{0.25cm} Model Construction Methods
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Describe Procedures to Construct the Model       %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DANKNUGGIES.

## 3.3 \hspace{0.25cm} Application to the STUDY-GOES-HERE 
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Explain Model's Answers to Research Questions    %
[//]: 2) Contextualize Assumptions and Limitations to     %
[//]:    the Problem of Interest                          %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DANKNUGGIES.

## 3.4 \hspace{0.25cm} Model Limitations \& Appropriateness 
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Discuss the Limitations of this Approach as Seen %
[//]:    in the Results                                   %
[//]: 2) Carefully Check Model Assumptions and Validity:  %
[//]:    e.g., if Using Regression:                       %
[//]:       i) Thoroughly Examine Model Appropriateness   %
[//]:       ii) Plot Residuals vs. Fitted Values          %
[//]:       iii) Identify High-Leverage Points            %
[//]:       iv) Identify Influential Points. Fit the      %
[//]:           Model with/without Influential Points     %
[//]:       v) Identify any Outliers                      %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DANKNUGGIES.

\newpage

# 4 \hspace{0.25cm} The $k$-Nearest Neighbors Approach
## 4.1 \hspace{0.25cm} Assumptions
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Clearly Explain Assumptions Needed for Validity  %
[//]: 2) Discuss Limitations of the Approach              %
[//]: 3) Preview the Checks of Assumptions/Limitations    %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DANKNUGGIES. 

## 4.2 \hspace{0.25cm} Model Construction Methods
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Describe Procedures to Construct the Model       %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DANKNUGGIES.

## 4.3 \hspace{0.25cm} Application to the STUDY-GOES-HERE 
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Explain Model's Answers to Research Questions    %
[//]: 2) Contextualize Assumptions and Limitations to     %
[//]:    the Problem of Interest                          %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DANKNUGGIES.

## 4.4 \hspace{0.25cm} Model Limitations \& Appropriateness 
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Discuss the Limitations of this Approach as Seen %
[//]:    in the Results                                   %
[//]: 2) Carefully Check Model Assumptions and Validity:  %
[//]:    e.g., if Using Regression:                       %
[//]:       i) Thoroughly Examine Model Appropriateness   %
[//]:       ii) Plot Residuals vs. Fitted Values          %
[//]:       iii) Identify High-Leverage Points            %
[//]:       iv) Identify Influential Points. Fit the      %
[//]:           Model with/without Influential Points     %
[//]:       v) Identify any Outliers                      %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DANKNUGGIES.

\newpage

# 5 \hspace{0.25cm} Conclusions
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Create a Hollistic Summary of the Models and     %
[//]:    Compare them Qualitatively and Quantitatively    %
[//]: 2) If Appropriate, Choose a Superior Method and     %
[//]:    Review Results, Appropriateness, and Limitations %
[//]: 3) Draw Collective Conclusions between the Methods  %
[//]:    and Justify Results/Limitations/Implications by  %
[//]:    Referencing the Review of the Analysis.          %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

DANKNUGGIES.

\newpage

# Appendix
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
[//]: 1) Show R Code for All Computer Output/Results      %
[//]: %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this appendix, we feature the \texttt{R} code used to generate the results and visualizations featured in this report. We will feature four primary sections for code: (1) data collection and cleaning, (2) STRATEGY-ONE model selection and analysis, (3) STRATEGY-TWO model selection and analysis, \& (4) STRATEGY-THREE model selection and analysis. 

## Data Collection \& Cleaning
SUMMARY. Comments in the code highlight specific tasks.
```{r, eval=FALSE}
# Collect the Pima Indian Diabetes Data into a Dataframe
BigChungus <- read.csv('Diabetes.csv', header = TRUE)
```

\newpage

## Quadratic Discriminant Analysis
SUMMARY. Again, comments in the code reveal specific tasks. 
```{r, eval=FALSE}
# Bring in the MASS Library for QDA
library(MASS)

# Fit the QDA Model to the Diabetes Data
fitQDA <- qda(isDiabetic ~ .,
              data = BigChungus,
              prior = c(0.33, 0.67))
predictQDA <- predict(fitQDA, BigChungus)
classPredictions <- predictQDA$class

# Create the Confusion Matrix
Confusion <- table(BigChungus[,9],
                   classPredictions)
Confusion

# Estimate the Misclassification Rate
numCorrect <- sum(diag(Confusion))
numEstimated <- sum(Confusion)
accuracy <- numCorrect / numEstimated
misclassRate <- 1 - accuracy
misclassRate

# Now Use Leave-One-Out Cross Validation
n <- nrow(BigChungus)
classPredictions <- rep(0, n)
for (i in 1:n) {
  fitQDA <- qda(isDiabetic ~ .,
                data = BigChungus[-i,],
                prior = c(0.33, 0.67))
  predictQDA <- predict(fitQDA, BigChungus[i,])
  classPredictions[i] <- as.numeric(predictQDA$class) - 1
}

# Create the Confusion Matrix
Confusion <- table(BigChungus[,9],
                   classPredictions)
Confusion

# Estimate the Misclassification Rate
numCorrect <- sum(diag(Confusion))
numEstimated <- sum(Confusion)
accuracy <- numCorrect / numEstimated
misclassRate <- 1 - accuracy
misclassRate
```

\newpage

## Logistic Regression
SUMMARY. Again, comments in the code reveal specific tasks. 
```{r, eval=FALSE}
# Bring in the NNET Library for Logistic Regression
library(nnet)

# Begin Classifying by Logistic Regression
lrFit <- multinom(isDiabetic ~ .,
                  data = BigChungus,
                  trace = FALSE,
                  maxit = 10000)
coe <- summary(lrFit)$coefficients
LittleChungus <- BigChungus[-9]
nman <- t(LittleChungus)
logodds <- coe[1] + coe[-1] %*% nman
logodds <- cbind(0, t(logodds))
class <- apply(logodds, 1, which.max)
class <- class - 1

#Construct Confusion Matrix
Confusion <- table(BigChungus[,9],
                   class)
Confusion

# Estimate the Misclassification Rate
numCorrect <- sum(diag(Confusion))
numEstimated <- sum(Confusion)
accuracy <- numCorrect / numEstimated
misclassRate <- 1 - accuracy
misclassRate

# Now Try Leave-One-Out Cross-Validation
n <- length(BigChungus$isDiabetic)
pcv <- rep(0, n)

for (i in 1:n) {
  lrFit <- multinom(isDiabetic ~ .,
                    data = BigChungus[-i,],
                    trace = FALSE,
                    maxit = 10000)
  coe <- summary(lrFit)$coefficients
  tman <- t(BigChungus[i,-9])
  logodds <- coe[1] + coe[-1] %*% tman
  logodds <- cbind(0, t(logodds))
  pcv[i] <- which.max(logodds) - 1
}

#Construct Confusion Matrix
Confusion <- table(BigChungus[,9],pcv)
Confusion

# Estimate the Misclassification Rate
numCorrect <- sum(diag(Confusion))
numEstimated <- sum(Confusion)
accuracy <- numCorrect / numEstimated
misclassRate <- 1 - accuracy
misclassRate
```


\newpage

## $k$-Nearest Neighbors
SUMMARY. Again, comments in the code reveal specific tasks. 
```{r, eval=FALSE}
# Ca$h Money
```